{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "003d3879",
   "metadata": {},
   "source": [
    "# Подготовка модели распознавания рукописных букв и цифр"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6318c5e",
   "metadata": {},
   "source": [
    "## Установка и импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9422ab4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install numpy\\n!pip install matplotlib\\n!pip install torch torchvision torchinfo\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install torch torchvision torchinfo\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44f50192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "from torchinfo import summary\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from torchvision.datasets import EMNIST\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fdd6028",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c53445",
   "metadata": {},
   "source": [
    "## Знакомство с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17fa0c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EMNIST('data/', 'balanced', download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b2224a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '0',\n",
       " 1: '1',\n",
       " 2: '2',\n",
       " 3: '3',\n",
       " 4: '4',\n",
       " 5: '5',\n",
       " 6: '6',\n",
       " 7: '7',\n",
       " 8: '8',\n",
       " 9: '9',\n",
       " 10: 'A',\n",
       " 11: 'B',\n",
       " 12: 'C',\n",
       " 13: 'D',\n",
       " 14: 'E',\n",
       " 15: 'F',\n",
       " 16: 'G',\n",
       " 17: 'H',\n",
       " 18: 'I',\n",
       " 19: 'J',\n",
       " 20: 'K',\n",
       " 21: 'L',\n",
       " 22: 'M',\n",
       " 23: 'N',\n",
       " 24: 'O',\n",
       " 25: 'P',\n",
       " 26: 'Q',\n",
       " 27: 'R',\n",
       " 28: 'S',\n",
       " 29: 'T',\n",
       " 30: 'U',\n",
       " 31: 'V',\n",
       " 32: 'W',\n",
       " 33: 'X',\n",
       " 34: 'Y',\n",
       " 35: 'Z',\n",
       " 36: 'a',\n",
       " 37: 'b',\n",
       " 38: 'd',\n",
       " 39: 'e',\n",
       " 40: 'f',\n",
       " 41: 'g',\n",
       " 42: 'h',\n",
       " 43: 'n',\n",
       " 44: 'q',\n",
       " 45: 'r',\n",
       " 46: 't'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/EMNIST/raw/emnist-balanced-mapping.txt', 'r') as file:\n",
    "    mapping = {}\n",
    "    for row in file:\n",
    "        label, code = row.split(' ')\n",
    "        mapping[int(label)] = chr(int(code))\n",
    "\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2fd04e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('myapp', 'mapping.pkl'), 'wb') as file:\n",
    "    pickle.dump(mapping, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c957a2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 5, figsize=(20, 5))\n",
    "for i in range(5):\n",
    "    axs[i].imshow(dataset[i][0])\n",
    "    axs[i].set_title(mapping[dataset[i][1]])\n",
    "    axs[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "875258d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение: 0.18\n",
      "Стандартное отклонение: 0.33\n"
     ]
    }
   ],
   "source": [
    "# Найдем среднее и стандартное отклонение тренировочной подвыборки\n",
    "\n",
    "# Загрузка датасета с нужной трансформацией\n",
    "transform = ToTensor()\n",
    "dataset = EMNIST(root='./data', \n",
    "                 split='balanced', \n",
    "                 train=True, \n",
    "                 download=True, \n",
    "                 transform=transform)\n",
    "\n",
    "# Вычисление суммы и суммы квадратов\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "num_samples = 0\n",
    "\n",
    "for image, _ in dataset:\n",
    "    num_samples += 1\n",
    "    mean += image.mean()\n",
    "    std += image.std()\n",
    "\n",
    "# Деление на общее количество изображений для получения среднего и стандартного отклонения\n",
    "mean /= num_samples\n",
    "std /= num_samples\n",
    "\n",
    "print(f'Среднее значение: {mean:.2f}')\n",
    "print(f'Стандартное отклонение: {std:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0944ce3f",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "416241b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим тестовую и тренировочную выборку использовав для нормализации среднее и стандартное отклонение\n",
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize([mean], [std]) #[0.5], [0.5]\n",
    "])\n",
    "\n",
    "train_dataset = EMNIST('data/', 'balanced', download=False, train=True, transform=transform)\n",
    "val_dataset = EMNIST('data/', 'balanced', download=False, train=False, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1000, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "142754ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество классов: 47\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(mapping.keys())\n",
    "print(f'Количество классов: {n_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24e4aac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112800, 18800)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader.dataset), len(val_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d229d051",
   "metadata": {},
   "source": [
    "## Сборка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67d4215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=2),\n",
    "            nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2)) # попробовать поменять на AvgPool2d \n",
    "\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), nn.Flatten())\n",
    "        self.drop = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(in_features=64*7*7, out_features=1024)        \n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=256)\n",
    "        self.fc3 = nn.Linear(in_features=256, out_features=n_classes)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        #out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "37c1530d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN                                      [1, 47]                   --\n",
       "├─Sequential: 1-1                        [1, 32, 14, 14]           --\n",
       "│    └─Conv2d: 2-1                       [1, 32, 28, 28]           832\n",
       "│    └─ReLU: 2-2                         [1, 32, 28, 28]           --\n",
       "│    └─MaxPool2d: 2-3                    [1, 32, 14, 14]           --\n",
       "├─Sequential: 1-2                        [1, 3136]                 --\n",
       "│    └─Conv2d: 2-4                       [1, 64, 14, 14]           51,264\n",
       "│    └─BatchNorm2d: 2-5                  [1, 64, 14, 14]           128\n",
       "│    └─ReLU: 2-6                         [1, 64, 14, 14]           --\n",
       "│    └─MaxPool2d: 2-7                    [1, 64, 7, 7]             --\n",
       "│    └─Flatten: 2-8                      [1, 3136]                 --\n",
       "├─Dropout: 1-3                           [1, 3136]                 --\n",
       "├─Linear: 1-4                            [1, 1024]                 3,212,288\n",
       "├─Linear: 1-5                            [1, 256]                  262,400\n",
       "├─Linear: 1-6                            [1, 47]                   12,079\n",
       "==========================================================================================\n",
       "Total params: 3,538,991\n",
       "Trainable params: 3,538,991\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 14.19\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.41\n",
       "Params size (MB): 14.16\n",
       "Estimated Total Size (MB): 14.57\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = CNN(n_classes)\n",
    "summary(net, input_size=(1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "609dc230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Iter: 0 \tLoss: 3.8885931968688965\n",
      "Iter: 10 \tLoss: 2.1009011268615723\n",
      "Iter: 20 \tLoss: 1.2113605737686157\n",
      "Iter: 30 \tLoss: 0.9648927450180054\n",
      "Iter: 40 \tLoss: 0.7560625672340393\n",
      "Iter: 50 \tLoss: 0.7371654510498047\n",
      "Iter: 60 \tLoss: 0.6136975884437561\n",
      "Iter: 70 \tLoss: 0.5695996880531311\n",
      "Iter: 80 \tLoss: 0.5894837975502014\n",
      "Iter: 90 \tLoss: 0.6182160377502441\n",
      "Iter: 100 \tLoss: 0.5766783356666565\n",
      "Iter: 110 \tLoss: 0.5645933747291565\n",
      "Mean Train Loss: 1.022777\n",
      "\n",
      "Val Loss: 0.524622 \tAccuracy: 0.829095744680851\n",
      "\n",
      "Epoch: 1\n",
      "Iter: 0 \tLoss: 0.536291241645813\n",
      "Iter: 10 \tLoss: 0.5647483468055725\n",
      "Iter: 20 \tLoss: 0.5053637027740479\n",
      "Iter: 30 \tLoss: 0.5080662369728088\n",
      "Iter: 40 \tLoss: 0.4911615550518036\n",
      "Iter: 50 \tLoss: 0.4869767427444458\n",
      "Iter: 60 \tLoss: 0.5135194063186646\n",
      "Iter: 70 \tLoss: 0.4446592926979065\n",
      "Iter: 80 \tLoss: 0.48287907242774963\n",
      "Iter: 90 \tLoss: 0.5411667227745056\n",
      "Iter: 100 \tLoss: 0.5028228759765625\n",
      "Iter: 110 \tLoss: 0.4570547938346863\n",
      "Mean Train Loss: 0.510638\n",
      "\n",
      "Epoch: 2\n",
      "Iter: 0 \tLoss: 0.5019035339355469\n",
      "Iter: 10 \tLoss: 0.5000226497650146\n",
      "Iter: 20 \tLoss: 0.4298376441001892\n",
      "Iter: 30 \tLoss: 0.4636969268321991\n",
      "Iter: 40 \tLoss: 0.450798898935318\n",
      "Iter: 50 \tLoss: 0.44570213556289673\n",
      "Iter: 60 \tLoss: 0.445768803358078\n",
      "Iter: 70 \tLoss: 0.4511180818080902\n",
      "Iter: 80 \tLoss: 0.41647934913635254\n",
      "Iter: 90 \tLoss: 0.4684593677520752\n",
      "Iter: 100 \tLoss: 0.5090264081954956\n",
      "Iter: 110 \tLoss: 0.47082948684692383\n",
      "Mean Train Loss: 0.467710\n",
      "\n",
      "Epoch: 3\n",
      "Iter: 0 \tLoss: 0.4808216691017151\n",
      "Iter: 10 \tLoss: 0.4529362916946411\n",
      "Iter: 20 \tLoss: 0.43101638555526733\n",
      "Iter: 30 \tLoss: 0.4034665822982788\n",
      "Iter: 40 \tLoss: 0.3710528612136841\n",
      "Iter: 50 \tLoss: 0.4245118498802185\n",
      "Iter: 60 \tLoss: 0.4206436574459076\n",
      "Iter: 70 \tLoss: 0.47911491990089417\n",
      "Iter: 80 \tLoss: 0.43382880091667175\n",
      "Iter: 90 \tLoss: 0.42841923236846924\n",
      "Iter: 100 \tLoss: 0.4591273069381714\n",
      "Iter: 110 \tLoss: 0.4195573925971985\n",
      "Mean Train Loss: 0.434840\n",
      "\n",
      "Epoch: 4\n",
      "Iter: 0 \tLoss: 0.3743596374988556\n",
      "Iter: 10 \tLoss: 0.362232506275177\n",
      "Iter: 20 \tLoss: 0.40730905532836914\n",
      "Iter: 30 \tLoss: 0.42132699489593506\n",
      "Iter: 40 \tLoss: 0.36726829409599304\n",
      "Iter: 50 \tLoss: 0.40803542733192444\n",
      "Iter: 60 \tLoss: 0.4091680943965912\n",
      "Iter: 70 \tLoss: 0.47658148407936096\n",
      "Iter: 80 \tLoss: 0.45834964513778687\n",
      "Iter: 90 \tLoss: 0.38860341906547546\n",
      "Iter: 100 \tLoss: 0.36786505579948425\n",
      "Iter: 110 \tLoss: 0.4495871961116791\n",
      "Mean Train Loss: 0.411933\n",
      "\n",
      "Epoch: 5\n",
      "Iter: 0 \tLoss: 0.3849004805088043\n",
      "Iter: 10 \tLoss: 0.4255041480064392\n",
      "Iter: 20 \tLoss: 0.37814879417419434\n",
      "Iter: 30 \tLoss: 0.35364317893981934\n",
      "Iter: 40 \tLoss: 0.3868361711502075\n",
      "Iter: 50 \tLoss: 0.40790149569511414\n",
      "Iter: 60 \tLoss: 0.37263646721839905\n",
      "Iter: 70 \tLoss: 0.4709535837173462\n",
      "Iter: 80 \tLoss: 0.43068593740463257\n",
      "Iter: 90 \tLoss: 0.368747353553772\n",
      "Iter: 100 \tLoss: 0.3677173852920532\n",
      "Iter: 110 \tLoss: 0.4495118260383606\n",
      "Mean Train Loss: 0.401599\n",
      "\n",
      "Val Loss: 0.396759 \tAccuracy: 0.864095744680851\n",
      "\n",
      "Epoch: 6\n",
      "Iter: 0 \tLoss: 0.40737563371658325\n",
      "Iter: 10 \tLoss: 0.436767578125\n",
      "Iter: 20 \tLoss: 0.42210420966148376\n",
      "Iter: 30 \tLoss: 0.3619556128978729\n",
      "Iter: 40 \tLoss: 0.3770771324634552\n",
      "Iter: 50 \tLoss: 0.3758716285228729\n",
      "Iter: 60 \tLoss: 0.42440640926361084\n",
      "Iter: 70 \tLoss: 0.3521183729171753\n",
      "Iter: 80 \tLoss: 0.39131197333335876\n",
      "Iter: 90 \tLoss: 0.3692063093185425\n",
      "Iter: 100 \tLoss: 0.41396406292915344\n",
      "Iter: 110 \tLoss: 0.46753841638565063\n",
      "Mean Train Loss: 0.389041\n",
      "\n",
      "Epoch: 7\n",
      "Iter: 0 \tLoss: 0.3956741690635681\n",
      "Iter: 10 \tLoss: 0.3101293742656708\n",
      "Iter: 20 \tLoss: 0.38179701566696167\n",
      "Iter: 30 \tLoss: 0.38226020336151123\n",
      "Iter: 40 \tLoss: 0.3794868588447571\n",
      "Iter: 50 \tLoss: 0.38097262382507324\n",
      "Iter: 60 \tLoss: 0.35421112179756165\n",
      "Iter: 70 \tLoss: 0.35462409257888794\n",
      "Iter: 80 \tLoss: 0.36266738176345825\n",
      "Iter: 90 \tLoss: 0.3950551450252533\n",
      "Iter: 100 \tLoss: 0.40472352504730225\n",
      "Iter: 110 \tLoss: 0.3804275691509247\n",
      "Mean Train Loss: 0.376115\n",
      "\n",
      "Epoch: 8\n",
      "Iter: 0 \tLoss: 0.3752378821372986\n",
      "Iter: 10 \tLoss: 0.38360515236854553\n",
      "Iter: 20 \tLoss: 0.37515726685523987\n",
      "Iter: 30 \tLoss: 0.3547770380973816\n",
      "Iter: 40 \tLoss: 0.30359145998954773\n",
      "Iter: 50 \tLoss: 0.38466283679008484\n",
      "Iter: 60 \tLoss: 0.3630577325820923\n",
      "Iter: 70 \tLoss: 0.3653511703014374\n",
      "Iter: 80 \tLoss: 0.36022162437438965\n",
      "Iter: 90 \tLoss: 0.37491437792778015\n",
      "Iter: 100 \tLoss: 0.34714657068252563\n",
      "Iter: 110 \tLoss: 0.3221719563007355\n",
      "Mean Train Loss: 0.361172\n",
      "\n",
      "Epoch: 9\n",
      "Iter: 0 \tLoss: 0.3787247836589813\n",
      "Iter: 10 \tLoss: 0.3318261504173279\n",
      "Iter: 20 \tLoss: 0.33480536937713623\n",
      "Iter: 30 \tLoss: 0.36667191982269287\n",
      "Iter: 40 \tLoss: 0.3900502324104309\n",
      "Iter: 50 \tLoss: 0.3375116288661957\n",
      "Iter: 60 \tLoss: 0.37484148144721985\n",
      "Iter: 70 \tLoss: 0.36347663402557373\n",
      "Iter: 80 \tLoss: 0.3587391972541809\n",
      "Iter: 90 \tLoss: 0.3789326548576355\n",
      "Iter: 100 \tLoss: 0.34777432680130005\n",
      "Iter: 110 \tLoss: 0.38593193888664246\n",
      "Mean Train Loss: 0.351249\n",
      "\n",
      "Epoch: 10\n",
      "Iter: 0 \tLoss: 0.3113845884799957\n",
      "Iter: 10 \tLoss: 0.3114175796508789\n",
      "Iter: 20 \tLoss: 0.33072683215141296\n",
      "Iter: 30 \tLoss: 0.3321600556373596\n",
      "Iter: 40 \tLoss: 0.3200816214084625\n",
      "Iter: 50 \tLoss: 0.3330481946468353\n",
      "Iter: 60 \tLoss: 0.34424278140068054\n",
      "Iter: 70 \tLoss: 0.3500671982765198\n",
      "Iter: 80 \tLoss: 0.33572226762771606\n",
      "Iter: 90 \tLoss: 0.3373991847038269\n",
      "Iter: 100 \tLoss: 0.35451117157936096\n",
      "Iter: 110 \tLoss: 0.3560616374015808\n",
      "Mean Train Loss: 0.347794\n",
      "\n",
      "Val Loss: 0.350109 \tAccuracy: 0.878031914893617\n",
      "\n",
      "Epoch: 11\n",
      "Iter: 0 \tLoss: 0.3517277240753174\n",
      "Iter: 10 \tLoss: 0.3627829849720001\n",
      "Iter: 20 \tLoss: 0.36052918434143066\n",
      "Iter: 30 \tLoss: 0.33434176445007324\n",
      "Iter: 40 \tLoss: 0.3331693410873413\n",
      "Iter: 50 \tLoss: 0.3281049132347107\n",
      "Iter: 60 \tLoss: 0.3759273588657379\n",
      "Iter: 70 \tLoss: 0.3065485656261444\n",
      "Iter: 80 \tLoss: 0.3243412673473358\n",
      "Iter: 90 \tLoss: 0.3633950352668762\n",
      "Iter: 100 \tLoss: 0.3273341655731201\n",
      "Iter: 110 \tLoss: 0.37289637327194214\n",
      "Mean Train Loss: 0.338499\n",
      "\n",
      "Epoch: 12\n",
      "Iter: 0 \tLoss: 0.3193170130252838\n",
      "Iter: 10 \tLoss: 0.3034713566303253\n",
      "Iter: 20 \tLoss: 0.3339170813560486\n",
      "Iter: 30 \tLoss: 0.34334418177604675\n",
      "Iter: 40 \tLoss: 0.3754439055919647\n",
      "Iter: 50 \tLoss: 0.3458040952682495\n",
      "Iter: 60 \tLoss: 0.32995763421058655\n",
      "Iter: 70 \tLoss: 0.3614206314086914\n",
      "Iter: 80 \tLoss: 0.3144490122795105\n",
      "Iter: 90 \tLoss: 0.3762366771697998\n",
      "Iter: 100 \tLoss: 0.3043343424797058\n",
      "Iter: 110 \tLoss: 0.3273200988769531\n",
      "Mean Train Loss: 0.334289\n",
      "\n",
      "Epoch: 13\n",
      "Iter: 0 \tLoss: 0.2933182120323181\n",
      "Iter: 10 \tLoss: 0.30905911326408386\n",
      "Iter: 20 \tLoss: 0.3450801968574524\n",
      "Iter: 30 \tLoss: 0.33000680804252625\n",
      "Iter: 40 \tLoss: 0.3635188341140747\n",
      "Iter: 50 \tLoss: 0.3259693682193756\n",
      "Iter: 60 \tLoss: 0.33593636751174927\n",
      "Iter: 70 \tLoss: 0.3109569847583771\n",
      "Iter: 80 \tLoss: 0.322866827249527\n",
      "Iter: 90 \tLoss: 0.3357698619365692\n",
      "Iter: 100 \tLoss: 0.34493488073349\n",
      "Iter: 110 \tLoss: 0.3330729305744171\n",
      "Mean Train Loss: 0.321990\n",
      "\n",
      "Epoch: 14\n",
      "Iter: 0 \tLoss: 0.2654939591884613\n",
      "Iter: 10 \tLoss: 0.2809918522834778\n",
      "Iter: 20 \tLoss: 0.3147938549518585\n",
      "Iter: 30 \tLoss: 0.3111308813095093\n",
      "Iter: 40 \tLoss: 0.29522866010665894\n",
      "Iter: 50 \tLoss: 0.3092925250530243\n",
      "Iter: 60 \tLoss: 0.331746906042099\n",
      "Iter: 70 \tLoss: 0.34371036291122437\n",
      "Iter: 80 \tLoss: 0.34977665543556213\n",
      "Iter: 90 \tLoss: 0.3062663972377777\n",
      "Iter: 100 \tLoss: 0.38037410378456116\n",
      "Iter: 110 \tLoss: 0.33877116441726685\n",
      "Mean Train Loss: 0.318873\n",
      "\n",
      "Epoch: 15\n",
      "Iter: 0 \tLoss: 0.3151833415031433\n",
      "Iter: 10 \tLoss: 0.3388516902923584\n",
      "Iter: 20 \tLoss: 0.31165948510169983\n",
      "Iter: 30 \tLoss: 0.35068845748901367\n",
      "Iter: 40 \tLoss: 0.29322561621665955\n",
      "Iter: 50 \tLoss: 0.3361469507217407\n",
      "Iter: 60 \tLoss: 0.3509742319583893\n",
      "Iter: 70 \tLoss: 0.3008086085319519\n",
      "Iter: 80 \tLoss: 0.35710132122039795\n",
      "Iter: 90 \tLoss: 0.28595292568206787\n",
      "Iter: 100 \tLoss: 0.3218793570995331\n",
      "Iter: 110 \tLoss: 0.3031306564807892\n",
      "Mean Train Loss: 0.313312\n",
      "\n",
      "Val Loss: 0.328815 \tAccuracy: 0.8852127659574468\n",
      "\n",
      "Epoch: 16\n",
      "Iter: 0 \tLoss: 0.32172489166259766\n",
      "Iter: 10 \tLoss: 0.299282044172287\n",
      "Iter: 20 \tLoss: 0.31861093640327454\n",
      "Iter: 30 \tLoss: 0.294808030128479\n",
      "Iter: 40 \tLoss: 0.25841209292411804\n",
      "Iter: 50 \tLoss: 0.3302242159843445\n",
      "Iter: 60 \tLoss: 0.3164638578891754\n",
      "Iter: 70 \tLoss: 0.3105453550815582\n",
      "Iter: 80 \tLoss: 0.29521337151527405\n",
      "Iter: 90 \tLoss: 0.3173762559890747\n",
      "Iter: 100 \tLoss: 0.31514132022857666\n",
      "Iter: 110 \tLoss: 0.2960960566997528\n",
      "Mean Train Loss: 0.306631\n",
      "\n",
      "Epoch: 17\n",
      "Iter: 0 \tLoss: 0.2600541412830353\n",
      "Iter: 10 \tLoss: 0.27800223231315613\n",
      "Iter: 20 \tLoss: 0.2985222339630127\n",
      "Iter: 30 \tLoss: 0.28954118490219116\n",
      "Iter: 40 \tLoss: 0.25872310996055603\n",
      "Iter: 50 \tLoss: 0.3159995675086975\n",
      "Iter: 60 \tLoss: 0.29928264021873474\n",
      "Iter: 70 \tLoss: 0.3574056625366211\n",
      "Iter: 80 \tLoss: 0.2865009903907776\n",
      "Iter: 90 \tLoss: 0.30564799904823303\n",
      "Iter: 100 \tLoss: 0.2798435091972351\n",
      "Iter: 110 \tLoss: 0.3112276792526245\n",
      "Mean Train Loss: 0.303904\n",
      "\n",
      "Epoch: 18\n",
      "Iter: 0 \tLoss: 0.29751765727996826\n",
      "Iter: 10 \tLoss: 0.30129286646842957\n",
      "Iter: 20 \tLoss: 0.3226863741874695\n",
      "Iter: 30 \tLoss: 0.3735758662223816\n",
      "Iter: 40 \tLoss: 0.28397268056869507\n",
      "Iter: 50 \tLoss: 0.3376704454421997\n",
      "Iter: 60 \tLoss: 0.32991236448287964\n",
      "Iter: 70 \tLoss: 0.3202061355113983\n",
      "Iter: 80 \tLoss: 0.32433632016181946\n",
      "Iter: 90 \tLoss: 0.2772075831890106\n",
      "Iter: 100 \tLoss: 0.31981077790260315\n",
      "Iter: 110 \tLoss: 0.25092849135398865\n",
      "Mean Train Loss: 0.297429\n",
      "\n",
      "Epoch: 19\n",
      "Iter: 0 \tLoss: 0.26998284459114075\n",
      "Iter: 10 \tLoss: 0.282390296459198\n",
      "Iter: 20 \tLoss: 0.30819886922836304\n",
      "Iter: 30 \tLoss: 0.2657798230648041\n",
      "Iter: 40 \tLoss: 0.2805297374725342\n",
      "Iter: 50 \tLoss: 0.274111807346344\n",
      "Iter: 60 \tLoss: 0.29350146651268005\n",
      "Iter: 70 \tLoss: 0.3109343349933624\n",
      "Iter: 80 \tLoss: 0.2780986428260803\n",
      "Iter: 90 \tLoss: 0.295674204826355\n",
      "Iter: 100 \tLoss: 0.30577391386032104\n",
      "Iter: 110 \tLoss: 0.3235446512699127\n",
      "Mean Train Loss: 0.290854\n",
      "\n",
      "Val Loss: 0.325064 \tAccuracy: 0.887127659574468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train ver 1\n",
    "def train_v1(model, optimizer, loss_f, train_loader, val_loader, n_epoch, val_fre):\n",
    "    model.train()\n",
    "    for epoch in range(n_epoch):\n",
    "        loss_sum = 0\n",
    "        print(f'Epoch: {epoch}')\n",
    "        for step, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data).squeeze(1)\n",
    "            loss = loss_f(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += loss.item()\n",
    "            if step % 10 == 0:\n",
    "                print(f'Iter: {step} \\tLoss: {loss.item()}')\n",
    "        print(f'Mean Train Loss: {loss_sum / (step + 1):.6f}', end='\\n\\n')\n",
    "        if (epoch) % val_fre == 0:\n",
    "            validate_v1(model, val_loader)\n",
    "    validate_v1(model, val_loader)\n",
    "            \n",
    "def validate_v1(model, val_loader):\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    correct = 0\n",
    "    for step, (data, target) in enumerate(val_loader):\n",
    "        with torch.no_grad():\n",
    "            output = model(data).squeeze(1)\n",
    "            loss = loss_f(output, target)\n",
    "        loss_sum += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    acc = correct / len(val_loader.dataset)\n",
    "    print(f'Val Loss: {loss_sum / (step + 1):.6f} \\tAccuracy: {acc}', end='\\n\\n')\n",
    "    model.train()\n",
    "\n",
    "learning_rate = 1e-3\n",
    "n_epoch = 20\n",
    "val_fre = 5\n",
    "fileName = 'CNN_ver1.pth'\n",
    "model = CNN(n_classes)\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_v1(model, optimizer, loss_f, train_loader, val_loader, n_epoch, val_fre)\n",
    "torch.save(model.state_dict(), f'checkpoints/{fileName}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "645b9f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Iter: 0 \tLoss: 3.871805191040039\n",
      "Iter: 10 \tLoss: 2.631775379180908\n",
      "Iter: 20 \tLoss: 1.5453463792800903\n",
      "Iter: 30 \tLoss: 1.0800282955169678\n",
      "Iter: 40 \tLoss: 0.91273033618927\n",
      "Iter: 50 \tLoss: 0.7927713990211487\n",
      "Iter: 60 \tLoss: 0.7607216238975525\n",
      "Iter: 70 \tLoss: 0.6534305810928345\n",
      "Iter: 80 \tLoss: 0.6798677444458008\n",
      "Iter: 90 \tLoss: 0.575345516204834\n",
      "Iter: 100 \tLoss: 0.6217457056045532\n",
      "Iter: 110 \tLoss: 0.5985150933265686\n",
      "Mean Train Loss: 1.140232\n",
      "\n",
      "Val Loss: 0.535903 \tAccuracy: 0.8265425531914894\n",
      "\n",
      "Epoch: 1\n",
      "Iter: 0 \tLoss: 0.5302228927612305\n",
      "Iter: 10 \tLoss: 0.5996345281600952\n",
      "Iter: 20 \tLoss: 0.5512940287590027\n",
      "Iter: 30 \tLoss: 0.4977559745311737\n",
      "Iter: 40 \tLoss: 0.5787631273269653\n",
      "Iter: 50 \tLoss: 0.5496382117271423\n",
      "Iter: 60 \tLoss: 0.5113751888275146\n",
      "Iter: 70 \tLoss: 0.43044158816337585\n",
      "Iter: 80 \tLoss: 0.44646015763282776\n",
      "Iter: 90 \tLoss: 0.5368689298629761\n",
      "Iter: 100 \tLoss: 0.4781939685344696\n",
      "Iter: 110 \tLoss: 0.4818994402885437\n",
      "Mean Train Loss: 0.514621\n",
      "\n",
      "Epoch: 2\n",
      "Iter: 0 \tLoss: 0.5007568597793579\n",
      "Iter: 10 \tLoss: 0.5362820625305176\n",
      "Iter: 20 \tLoss: 0.4346783459186554\n",
      "Iter: 30 \tLoss: 0.42227843403816223\n",
      "Iter: 40 \tLoss: 0.4518834948539734\n",
      "Iter: 50 \tLoss: 0.5592285394668579\n",
      "Iter: 60 \tLoss: 0.44180959463119507\n",
      "Iter: 70 \tLoss: 0.5231431126594543\n",
      "Iter: 80 \tLoss: 0.44347503781318665\n",
      "Iter: 90 \tLoss: 0.48430126905441284\n",
      "Iter: 100 \tLoss: 0.526896595954895\n",
      "Iter: 110 \tLoss: 0.4737253189086914\n",
      "Mean Train Loss: 0.467143\n",
      "\n",
      "Epoch: 3\n",
      "Iter: 0 \tLoss: 0.43809184432029724\n",
      "Iter: 10 \tLoss: 0.4706054627895355\n",
      "Iter: 20 \tLoss: 0.4276202321052551\n",
      "Iter: 30 \tLoss: 0.47649437189102173\n",
      "Iter: 40 \tLoss: 0.4244728684425354\n",
      "Iter: 50 \tLoss: 0.43555086851119995\n",
      "Iter: 60 \tLoss: 0.4825979471206665\n",
      "Iter: 70 \tLoss: 0.4541819095611572\n",
      "Iter: 80 \tLoss: 0.42769119143486023\n",
      "Iter: 90 \tLoss: 0.41669702529907227\n",
      "Iter: 100 \tLoss: 0.42527398467063904\n",
      "Iter: 110 \tLoss: 0.44293370842933655\n",
      "Mean Train Loss: 0.440092\n",
      "\n",
      "Epoch: 4\n",
      "Iter: 0 \tLoss: 0.40079304575920105\n",
      "Iter: 10 \tLoss: 0.42933133244514465\n",
      "Iter: 20 \tLoss: 0.4455219805240631\n",
      "Iter: 30 \tLoss: 0.39571863412857056\n",
      "Iter: 40 \tLoss: 0.4342661499977112\n",
      "Iter: 50 \tLoss: 0.4624340236186981\n",
      "Iter: 60 \tLoss: 0.3492026627063751\n",
      "Iter: 70 \tLoss: 0.40115535259246826\n",
      "Iter: 80 \tLoss: 0.40693244338035583\n",
      "Iter: 90 \tLoss: 0.4103361964225769\n",
      "Iter: 100 \tLoss: 0.41559675335884094\n",
      "Iter: 110 \tLoss: 0.43765348196029663\n",
      "Mean Train Loss: 0.416096\n",
      "\n",
      "Epoch: 5\n",
      "Iter: 0 \tLoss: 0.38301071524620056\n",
      "Iter: 10 \tLoss: 0.3935277462005615\n",
      "Iter: 20 \tLoss: 0.45984721183776855\n",
      "Iter: 30 \tLoss: 0.37118539214134216\n",
      "Iter: 40 \tLoss: 0.40378284454345703\n",
      "Iter: 50 \tLoss: 0.3634319007396698\n",
      "Iter: 60 \tLoss: 0.40789663791656494\n",
      "Iter: 70 \tLoss: 0.4030786156654358\n",
      "Iter: 80 \tLoss: 0.4189484119415283\n",
      "Iter: 90 \tLoss: 0.3584711253643036\n",
      "Iter: 100 \tLoss: 0.3972570300102234\n",
      "Iter: 110 \tLoss: 0.4607996940612793\n",
      "Mean Train Loss: 0.403002\n",
      "\n",
      "Val Loss: 0.385500 \tAccuracy: 0.8620744680851063\n",
      "\n",
      "Epoch: 6\n",
      "Iter: 0 \tLoss: 0.35068556666374207\n",
      "Iter: 10 \tLoss: 0.3625674843788147\n",
      "Iter: 20 \tLoss: 0.33342471718788147\n",
      "Iter: 30 \tLoss: 0.4000743329524994\n",
      "Iter: 40 \tLoss: 0.3321547508239746\n",
      "Iter: 50 \tLoss: 0.4896375834941864\n",
      "Iter: 60 \tLoss: 0.37057310342788696\n",
      "Iter: 70 \tLoss: 0.3348459303379059\n",
      "Iter: 80 \tLoss: 0.4169711172580719\n",
      "Iter: 90 \tLoss: 0.3978686034679413\n",
      "Iter: 100 \tLoss: 0.3723858892917633\n",
      "Iter: 110 \tLoss: 0.4253751039505005\n",
      "Mean Train Loss: 0.390209\n",
      "\n",
      "Epoch: 7\n",
      "Iter: 0 \tLoss: 0.3694285452365875\n",
      "Iter: 10 \tLoss: 0.36514508724212646\n",
      "Iter: 20 \tLoss: 0.3659355044364929\n",
      "Iter: 30 \tLoss: 0.3628068268299103\n",
      "Iter: 40 \tLoss: 0.30349183082580566\n",
      "Iter: 50 \tLoss: 0.3631301820278168\n",
      "Iter: 60 \tLoss: 0.3304690420627594\n",
      "Iter: 70 \tLoss: 0.37897351384162903\n",
      "Iter: 80 \tLoss: 0.35640400648117065\n",
      "Iter: 90 \tLoss: 0.4026539623737335\n",
      "Iter: 100 \tLoss: 0.35501939058303833\n",
      "Iter: 110 \tLoss: 0.3612036108970642\n",
      "Mean Train Loss: 0.380761\n",
      "\n",
      "Epoch: 8\n",
      "Iter: 0 \tLoss: 0.3773544728755951\n",
      "Iter: 10 \tLoss: 0.36563509702682495\n",
      "Iter: 20 \tLoss: 0.35450243949890137\n",
      "Iter: 30 \tLoss: 0.3839890658855438\n",
      "Iter: 40 \tLoss: 0.4255554676055908\n",
      "Iter: 50 \tLoss: 0.3578740358352661\n",
      "Iter: 60 \tLoss: 0.3784502446651459\n",
      "Iter: 70 \tLoss: 0.3541710376739502\n",
      "Iter: 80 \tLoss: 0.3672953248023987\n",
      "Iter: 90 \tLoss: 0.37070363759994507\n",
      "Iter: 100 \tLoss: 0.34107357263565063\n",
      "Iter: 110 \tLoss: 0.3998071253299713\n",
      "Mean Train Loss: 0.367985\n",
      "\n",
      "Epoch: 9\n",
      "Iter: 0 \tLoss: 0.3732820451259613\n",
      "Iter: 10 \tLoss: 0.3437381982803345\n",
      "Iter: 20 \tLoss: 0.3431544303894043\n",
      "Iter: 30 \tLoss: 0.34680071473121643\n",
      "Iter: 40 \tLoss: 0.38907483220100403\n",
      "Iter: 50 \tLoss: 0.36671221256256104\n",
      "Iter: 60 \tLoss: 0.3398823142051697\n",
      "Iter: 70 \tLoss: 0.3825165331363678\n",
      "Iter: 80 \tLoss: 0.35444676876068115\n",
      "Iter: 90 \tLoss: 0.3668382465839386\n",
      "Iter: 100 \tLoss: 0.41117215156555176\n",
      "Iter: 110 \tLoss: 0.33880385756492615\n",
      "Mean Train Loss: 0.359031\n",
      "\n",
      "Epoch: 10\n",
      "Iter: 0 \tLoss: 0.29307883977890015\n",
      "Iter: 10 \tLoss: 0.3442894518375397\n",
      "Iter: 20 \tLoss: 0.37339216470718384\n",
      "Iter: 30 \tLoss: 0.3931926488876343\n",
      "Iter: 40 \tLoss: 0.3990265429019928\n",
      "Iter: 50 \tLoss: 0.326760858297348\n",
      "Iter: 60 \tLoss: 0.4266209602355957\n",
      "Iter: 70 \tLoss: 0.35086676478385925\n",
      "Iter: 80 \tLoss: 0.30436721444129944\n",
      "Iter: 90 \tLoss: 0.4273371696472168\n",
      "Iter: 100 \tLoss: 0.37346163392066956\n",
      "Iter: 110 \tLoss: 0.33262741565704346\n",
      "Mean Train Loss: 0.349080\n",
      "\n",
      "Val Loss: 0.354706 \tAccuracy: 0.8753191489361702\n",
      "\n",
      "Epoch: 11\n",
      "Iter: 0 \tLoss: 0.3358316421508789\n",
      "Iter: 10 \tLoss: 0.3184584379196167\n",
      "Iter: 20 \tLoss: 0.3253275156021118\n",
      "Iter: 30 \tLoss: 0.2719208598136902\n",
      "Iter: 40 \tLoss: 0.3018946051597595\n",
      "Iter: 50 \tLoss: 0.399404913187027\n",
      "Iter: 60 \tLoss: 0.3293693959712982\n",
      "Iter: 70 \tLoss: 0.38011282682418823\n",
      "Iter: 80 \tLoss: 0.37497130036354065\n",
      "Iter: 90 \tLoss: 0.39818868041038513\n",
      "Iter: 100 \tLoss: 0.3592067062854767\n",
      "Iter: 110 \tLoss: 0.36258769035339355\n",
      "Mean Train Loss: 0.340172\n",
      "\n",
      "Epoch: 12\n",
      "Iter: 0 \tLoss: 0.367065966129303\n",
      "Iter: 10 \tLoss: 0.31418293714523315\n",
      "Iter: 20 \tLoss: 0.29503968358039856\n",
      "Iter: 30 \tLoss: 0.38300520181655884\n",
      "Iter: 40 \tLoss: 0.3736671209335327\n",
      "Iter: 50 \tLoss: 0.3380402624607086\n",
      "Iter: 60 \tLoss: 0.39199990034103394\n",
      "Iter: 70 \tLoss: 0.30552372336387634\n",
      "Iter: 80 \tLoss: 0.34397101402282715\n",
      "Iter: 90 \tLoss: 0.34445181488990784\n",
      "Iter: 100 \tLoss: 0.33277949690818787\n",
      "Iter: 110 \tLoss: 0.36616605520248413\n",
      "Mean Train Loss: 0.334010\n",
      "\n",
      "Epoch: 13\n",
      "Iter: 0 \tLoss: 0.30467653274536133\n",
      "Iter: 10 \tLoss: 0.3126674294471741\n",
      "Iter: 20 \tLoss: 0.30280840396881104\n",
      "Iter: 30 \tLoss: 0.34562593698501587\n",
      "Iter: 40 \tLoss: 0.31207937002182007\n",
      "Iter: 50 \tLoss: 0.29257526993751526\n",
      "Iter: 60 \tLoss: 0.3219742774963379\n",
      "Iter: 70 \tLoss: 0.303480863571167\n",
      "Iter: 80 \tLoss: 0.3500882685184479\n",
      "Iter: 90 \tLoss: 0.251577228307724\n",
      "Iter: 100 \tLoss: 0.27812978625297546\n",
      "Iter: 110 \tLoss: 0.3034437596797943\n",
      "Mean Train Loss: 0.327377\n",
      "\n",
      "Epoch: 14\n",
      "Iter: 0 \tLoss: 0.33128511905670166\n",
      "Iter: 10 \tLoss: 0.32613199949264526\n",
      "Iter: 20 \tLoss: 0.3105276823043823\n",
      "Iter: 30 \tLoss: 0.3013881742954254\n",
      "Iter: 40 \tLoss: 0.3301609754562378\n",
      "Iter: 50 \tLoss: 0.3405659794807434\n",
      "Iter: 60 \tLoss: 0.2798730134963989\n",
      "Iter: 70 \tLoss: 0.29997992515563965\n",
      "Iter: 80 \tLoss: 0.3048365116119385\n",
      "Iter: 90 \tLoss: 0.37867650389671326\n",
      "Iter: 100 \tLoss: 0.31668582558631897\n",
      "Iter: 110 \tLoss: 0.3361647129058838\n",
      "Mean Train Loss: 0.323109\n",
      "\n",
      "Epoch: 15\n",
      "Iter: 0 \tLoss: 0.32959291338920593\n",
      "Iter: 10 \tLoss: 0.32690292596817017\n",
      "Iter: 20 \tLoss: 0.3188563287258148\n",
      "Iter: 30 \tLoss: 0.3183424472808838\n",
      "Iter: 40 \tLoss: 0.3240664601325989\n",
      "Iter: 50 \tLoss: 0.3249536156654358\n",
      "Iter: 60 \tLoss: 0.31303510069847107\n",
      "Iter: 70 \tLoss: 0.33830225467681885\n",
      "Iter: 80 \tLoss: 0.31523609161376953\n",
      "Iter: 90 \tLoss: 0.3279086947441101\n",
      "Iter: 100 \tLoss: 0.39271631836891174\n",
      "Iter: 110 \tLoss: 0.35529786348342896\n",
      "Mean Train Loss: 0.317715\n",
      "\n",
      "Val Loss: 0.342856 \tAccuracy: 0.8775531914893617\n",
      "\n",
      "Epoch: 16\n",
      "Iter: 0 \tLoss: 0.30581554770469666\n",
      "Iter: 10 \tLoss: 0.3593018651008606\n",
      "Iter: 20 \tLoss: 0.3087851405143738\n",
      "Iter: 30 \tLoss: 0.2942415475845337\n",
      "Iter: 40 \tLoss: 0.25027963519096375\n",
      "Iter: 50 \tLoss: 0.29264920949935913\n",
      "Iter: 60 \tLoss: 0.4007616639137268\n",
      "Iter: 70 \tLoss: 0.2749115824699402\n",
      "Iter: 80 \tLoss: 0.2967698276042938\n",
      "Iter: 90 \tLoss: 0.3250807523727417\n",
      "Iter: 100 \tLoss: 0.31072160601615906\n",
      "Iter: 110 \tLoss: 0.28645747900009155\n",
      "Mean Train Loss: 0.312583\n",
      "\n",
      "Epoch: 17\n",
      "Iter: 0 \tLoss: 0.3397746682167053\n",
      "Iter: 10 \tLoss: 0.27938857674598694\n",
      "Iter: 20 \tLoss: 0.2588769197463989\n",
      "Iter: 30 \tLoss: 0.2999967336654663\n",
      "Iter: 40 \tLoss: 0.27183952927589417\n",
      "Iter: 50 \tLoss: 0.3690870702266693\n",
      "Iter: 60 \tLoss: 0.35225263237953186\n",
      "Iter: 70 \tLoss: 0.3605720102787018\n",
      "Iter: 80 \tLoss: 0.3371720314025879\n",
      "Iter: 90 \tLoss: 0.33460187911987305\n",
      "Iter: 100 \tLoss: 0.3211042284965515\n",
      "Iter: 110 \tLoss: 0.31655997037887573\n",
      "Mean Train Loss: 0.308744\n",
      "\n",
      "Epoch: 18\n",
      "Iter: 0 \tLoss: 0.29598161578178406\n",
      "Iter: 10 \tLoss: 0.273629367351532\n",
      "Iter: 20 \tLoss: 0.31396326422691345\n",
      "Iter: 30 \tLoss: 0.24512791633605957\n",
      "Iter: 40 \tLoss: 0.2824903428554535\n",
      "Iter: 50 \tLoss: 0.2661416232585907\n",
      "Iter: 60 \tLoss: 0.32145699858665466\n",
      "Iter: 70 \tLoss: 0.23936821520328522\n",
      "Iter: 80 \tLoss: 0.27511274814605713\n",
      "Iter: 90 \tLoss: 0.33159926533699036\n",
      "Iter: 100 \tLoss: 0.34805843234062195\n",
      "Iter: 110 \tLoss: 0.2861669361591339\n",
      "Mean Train Loss: 0.303066\n",
      "\n",
      "Epoch: 19\n",
      "Iter: 0 \tLoss: 0.29832249879837036\n",
      "Iter: 10 \tLoss: 0.27736225724220276\n",
      "Iter: 20 \tLoss: 0.30280882120132446\n",
      "Iter: 30 \tLoss: 0.31872910261154175\n",
      "Iter: 40 \tLoss: 0.32468941807746887\n",
      "Iter: 50 \tLoss: 0.30481022596359253\n",
      "Iter: 60 \tLoss: 0.3771081268787384\n",
      "Iter: 70 \tLoss: 0.2832476496696472\n",
      "Iter: 80 \tLoss: 0.27056577801704407\n",
      "Iter: 90 \tLoss: 0.3273716866970062\n",
      "Iter: 100 \tLoss: 0.33526769280433655\n",
      "Iter: 110 \tLoss: 0.29701367020606995\n",
      "Mean Train Loss: 0.300075\n",
      "\n",
      "Val Loss: 0.329038 \tAccuracy: 0.8875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train ver 2\n",
    "def train_v2(model, optimizer, loss_f, train_loader, val_loader, n_epoch, val_freq):\n",
    "    model.train()\n",
    "    for epoch in range(n_epoch):\n",
    "        loss_sum = 0\n",
    "        print(f'Epoch: {epoch}')\n",
    "        for step, (images, labels) in enumerate(train_loader):\n",
    "            # Прямой запуск\n",
    "            outputs = model(images)\n",
    "            loss = loss_f(outputs, labels)\n",
    "\n",
    "            # Обратное распространение и оптимизатор\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                print(f'Iter: {step} \\tLoss: {loss.item()}')\n",
    "\n",
    "        print(f'Mean Train Loss: {loss_sum / (step + 1):.6f}', end='\\n\\n')\n",
    "\n",
    "        if (epoch) % val_freq == 0:\n",
    "            validate_v2(model, val_loader)\n",
    "\n",
    "    validate_v2(model, val_loader)\n",
    "\n",
    "\n",
    "def validate_v2(model, val_loader):\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    correct = 0\n",
    "    for step, (images, labels) in enumerate(val_loader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images).squeeze(1)\n",
    "            loss = loss_f(outputs, labels)\n",
    "        loss_sum += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, dim=1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = correct / len(val_loader.dataset)\n",
    "    print(f'Val Loss: {loss_sum / (step + 1):.6f} \\tAccuracy: {acc}', end='\\n\\n')\n",
    "    model.train()\n",
    "\n",
    "\n",
    "n_epoch = 20\n",
    "val_freq = 5\n",
    "fileName = 'CNN_ver2.pth'\n",
    "learning_rate = 1e-3\n",
    "n_classes = len(mapping.keys())\n",
    "model = CNN(n_classes)\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_v2(model, optimizer, loss_f, train_loader, val_loader, n_epoch, val_freq)\n",
    "torch.save(model.state_dict(), f'checkpoints/{fileName}')\n",
    "\n",
    "# Val Loss: 0.330132 \tAccuracy: 0.8827127659574469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f520c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.329038 \tAccuracy: 0.8875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Проверка достижения значения метрики в 87%\n",
    "fileName = 'CNN_ver2.pth'\n",
    "model = CNN(n_classes)\n",
    "model.load_state_dict(torch.load(f'checkpoints/{fileName}'))\n",
    "validate_v2(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81e27ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сериализация model и mapping в pickle\n",
    "with open(os.path.join('myapp', 'model.pkl'), 'wb') as file:\n",
    "    pickle.dump({\n",
    "        'model': model,\n",
    "        'mapping': mapping,\n",
    "        'val_acc': 0.8875\n",
    "    }, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25d4b170",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('myapp', 'model.pkl'), 'rb') as file:\n",
    "    test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb555ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_advanced",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
